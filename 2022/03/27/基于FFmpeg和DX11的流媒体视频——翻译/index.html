<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;example.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Pisces&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:-1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script><script src="/js/config.js"></script>
<meta name="description" content="基于FFMPEG 和 DirectX11的流媒体视频事情起因：因为工作需求，我需要使用ffmpeg进行硬解实时视频并显示到屏幕, 但是性能一直不太理想。偶然发现一篇英文博客与我的需求类似，所以我决定翻译这边英文博客，这是原文地址：https:&#x2F;&#x2F;medium.com&#x2F;swlh&#x2F;streaming-video-with-ffmpeg-and-directx-11-7395fcb372c4 在几个月之">
<meta property="og:type" content="article">
<meta property="og:title" content="基于FFmpeg和DX11的流媒体视频——翻译">
<meta property="og:url" content="http://example.com/2022/03/27/%E5%9F%BA%E4%BA%8EFFmpeg%E5%92%8CDX11%E7%9A%84%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%86%E9%A2%91%E2%80%94%E2%80%94%E7%BF%BB%E8%AF%91/index.html">
<meta property="og:site_name" content="mingxingren的博客">
<meta property="og:description" content="基于FFMPEG 和 DirectX11的流媒体视频事情起因：因为工作需求，我需要使用ffmpeg进行硬解实时视频并显示到屏幕, 但是性能一直不太理想。偶然发现一篇英文博客与我的需求类似，所以我决定翻译这边英文博客，这是原文地址：https:&#x2F;&#x2F;medium.com&#x2F;swlh&#x2F;streaming-video-with-ffmpeg-and-directx-11-7395fcb372c4 在几个月之">
<meta property="og:locale">
<meta property="article:published_time" content="2022-03-27T12:21:36.776Z">
<meta property="article:modified_time" content="2022-03-27T12:23:07.681Z">
<meta property="article:author" content="mingxingren">
<meta property="article:tag" content="windows">
<meta property="article:tag" content="DirectX">
<meta property="article:tag" content="ffmpeg">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2022/03/27/%E5%9F%BA%E4%BA%8EFFmpeg%E5%92%8CDX11%E7%9A%84%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%86%E9%A2%91%E2%80%94%E2%80%94%E7%BF%BB%E8%AF%91/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-Hans&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;example.com&#x2F;2022&#x2F;03&#x2F;27&#x2F;%E5%9F%BA%E4%BA%8EFFmpeg%E5%92%8CDX11%E7%9A%84%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%86%E9%A2%91%E2%80%94%E2%80%94%E7%BF%BB%E8%AF%91&#x2F;&quot;,&quot;path&quot;:&quot;2022&#x2F;03&#x2F;27&#x2F;基于FFmpeg和DX11的流媒体视频——翻译&#x2F;&quot;,&quot;title&quot;:&quot;基于FFmpeg和DX11的流媒体视频——翻译&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>基于FFmpeg和DX11的流媒体视频——翻译 | mingxingren的博客</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">mingxingren的博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8EFFMPEG-%E5%92%8C-DirectX11%E7%9A%84%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%86%E9%A2%91"><span class="nav-number">1.</span> <span class="nav-text">基于FFMPEG 和 DirectX11的流媒体视频</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E8%AE%BE%E7%BD%AE%E6%BA%90%E6%B5%81%E5%92%8C%E8%A7%86%E9%A2%91%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="nav-number">1.1.</span> <span class="nav-text">第一步：设置源流和视频解码器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%BD%AC%E6%8D%A2-NV12-%E4%B8%BA-RGBA"><span class="nav-number">1.2.</span> <span class="nav-text">第二步：转换 NV12 为 RGBA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E8%AE%BE%E7%BD%AE-DirectX11-%E6%B8%B2%E6%9F%93"><span class="nav-number">1.3.</span> <span class="nav-text">第三步：设置 DirectX11 渲染</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E4%BA%A4%E6%8D%A2%E7%BA%B9%E7%90%86%E9%A2%9C%E8%89%B2"><span class="nav-number">1.4.</span> <span class="nav-text">第四步：交换纹理颜色</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E6%B8%B2%E6%9F%93%E5%AE%9E%E9%99%85%E7%9A%84%E5%B8%A7"><span class="nav-number">1.5.</span> <span class="nav-text">第五步：渲染实际的帧</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E6%AD%A5%EF%BC%9A%E6%B8%B2%E6%9F%93%E5%AE%9E%E9%99%85%E5%B8%A7%E2%80%A6-%E5%8F%AF%E8%83%BD%E6%98%AF%E6%AD%A3%E7%A1%AE%E7%9A%84"><span class="nav-number">1.6.</span> <span class="nav-text">第六步：渲染实际帧… 可能是正确的</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="mingxingren"
      src="/images/avatar01.png">
  <p class="site-author-name" itemprop="name">mingxingren</p>
  <div class="site-description" itemprop="description">挖一口自己的井</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/27/%E5%9F%BA%E4%BA%8EFFmpeg%E5%92%8CDX11%E7%9A%84%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%86%E9%A2%91%E2%80%94%E2%80%94%E7%BF%BB%E8%AF%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar01.png">
      <meta itemprop="name" content="mingxingren">
      <meta itemprop="description" content="挖一口自己的井">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mingxingren的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于FFmpeg和DX11的流媒体视频——翻译
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-03-27 20:21:36 / 修改时间：20:23:07" itemprop="dateCreated datePublished" datetime="2022-03-27T20:21:36+08:00">2022-03-27</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="基于FFMPEG-和-DirectX11的流媒体视频"><a href="#基于FFMPEG-和-DirectX11的流媒体视频" class="headerlink" title="基于FFMPEG 和 DirectX11的流媒体视频"></a>基于FFMPEG 和 DirectX11的流媒体视频</h1><p>事情起因：因为工作需求，我需要使用ffmpeg进行硬解实时视频并显示到屏幕, 但是性能一直不太理想。偶然发现一篇英文博客与我的需求类似，所以我决定翻译这边英文博客，这是原文地址：<a target="_blank" rel="noopener" href="https://medium.com/swlh/streaming-video-with-ffmpeg-and-directx-11-7395fcb372c4">https://medium.com/swlh/streaming-video-with-ffmpeg-and-directx-11-7395fcb372c4</a></p>
<p>在几个月之前，我被分配开发一个低延迟的视频播放器。在之前，我只接触过FFmpeg没接触过DirectX11。但是我认为它应该不难。FFmpeg是非常受欢迎的，DirectX11也出现了很长一段时间了，并且我应该不会用到3D图形或者更复杂的东西。</p>
<p>所以，应该会有一些能借鉴的解码和渲染视频例子，是吧？</p>
<p>但很不幸，没有…， 因此才写这篇文章。</p>
<p>所以下一个对FFmpeg和DirectX11不熟悉的人不必为了显示视频而伤脑筋。</p>
<p>首先，我们需要搞清楚一些重要的事情</p>
<p>① 样例代码需要足够简单。我省略返回码检测的，错误处理等，我的观点是代码例子就只是例子（我会提供更全面得例子，但是你知道，知识产权等等）</p>
<p>② 我不会介绍硬件加速视频解码/渲染原理，因为它有点超出了本文的范围。此外，还有很多其他资源比我能更好地解释它</p>
<p>③ ffmpeg 支持相当多地协议和编码格式。RTSP 和 UDP 的例子都有用它，h264和h265编码同样用到ffmpeg，我相信很多人参考它。</p>
<p>④ 我使用CMake创建此工程，使它不依赖Visual Studio’s 编译平台（因为我们同样需要支持不需要DirectX的渲染）。这让事情变得更加有难度，这就是我为什么提到它</p>
<h2 id="第一步：设置源流和视频解码器"><a href="#第一步：设置源流和视频解码器" class="headerlink" title="第一步：设置源流和视频解码器"></a>第一步：设置源流和视频解码器</h2><p>这是ffmpeg这块的，只是设置格式上下文，解码上下文，和所有ffmpeg需要的结构体。对于此处，我参考了<a target="_blank" rel="noopener" href="https://ffmpeg.org/doxygen/3.4/hw__decode_8c_source.html">这个例子</a>和<a target="_blank" rel="noopener" href="https://github.com/moonlight-stream/moonlight-qt/blob/master/app/streaming/video/ffmpeg.cpp">MoonLight</a>的源码。</p>
<p>注意你需要以某种方式向 AVCodecContext 提供硬件设备类型。我选择与ffmpeg相同的方式执行此操作。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialize stream</span></span><br><span class="line"><span class="keyword">const</span> std::string hw_device_name = <span class="string">&quot;d3d11va&quot;</span>;</span><br><span class="line">AVHWDeviceType device_type = <span class="built_in">av_hwdevice_find_type_by_name</span>(hw_device_name.<span class="built_in">c_str</span>());</span><br><span class="line"><span class="comment">// set up codec context</span></span><br><span class="line">AVBufferRef* hw_device_ctx;</span><br><span class="line"><span class="built_in">av_hwdevice_ctx_create</span>(&amp;hw_device_ctx, device_type, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="number">0</span>);</span><br><span class="line">codec_ctx-&gt;hw_device_ctx = <span class="built_in">av_buffer_ref</span>(hw_device_ctx);</span><br><span class="line"><span class="comment">// open stream</span></span><br></pre></td></tr></table></figure>

<p>一旦设置完成，解码是相当简单的；它仅仅是从源流种获取AVPacket并且将它们解码成AVFrames这些事情。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AVPacket* packet = <span class="built_in">av_packet_alloc</span>();</span><br><span class="line"><span class="built_in">av_read_frame</span>(format_ctx, packet);</span><br><span class="line"><span class="built_in">avcodec_send_packet</span>(codec_ctx, packet);</span><br><span class="line">AVFrame* frame = <span class="built_in">av_frame_alloc</span>();</span><br><span class="line"><span class="built_in">avcodec_receive_frame</span>(codec_ctx, frame);</span><br></pre></td></tr></table></figure>

<p>这些都是简化的，但组在一起也不需要太麻烦。虽然我还不能将它显示到屏幕上，我想验证是否生成有效的帧，所以我认为我只需将它们写入bitmap来验证。</p>
<p>这里有个小问题</p>
<h2 id="第二步：转换-NV12-为-RGBA"><a href="#第二步：转换-NV12-为-RGBA" class="headerlink" title="第二步：转换 NV12 为 RGBA"></a>第二步：转换 NV12 为 RGBA</h2><p>创建一个 bitmap(并且当它转换成功后，使用DX11 swapchain呈现)，我需要RGBA格式的帧。然后这个解码器解出来的是 NV12格式，所以我使用 FFmpeg的<a target="_blank" rel="noopener" href="https://ffmpeg.org/doxygen/0.5/swscale-example_8c-source.html">swscale</a>将 AV_PIX_FMT_NV12 转换成 AV_PIX_FMT_RGBA。</p>
<p>设置 SwsContext就像调用单个函数一样简单</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SwsContext* conversion_ctx = <span class="built_in">sws_getContext</span>(</span><br><span class="line">        SRC_WIDTH, SRC_HEIGHT, AV_PIX_FMT_NV12,</span><br><span class="line">        DST_WIDTH, DST_HEIGHT, AV_PIX_FMT_RGBA,</span><br><span class="line">        SWS_BICUBLIN | SWS_BITEXACT, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</span><br></pre></td></tr></table></figure>

<p>当然，为了使用sws_scale(), 我们需要将帧数据从GPU转换到CPU. 利用ffmpeg的av_hwframe_transfer_data() 。有很多这样的<a target="_blank" rel="noopener" href="https://ffmpeg.org/doxygen/3.4/hw__decode_8c_source.html">例子</a></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// decode frame</span></span><br><span class="line">AVFrame* sw_frame = <span class="built_in">av_frame_alloc</span>();</span><br><span class="line"><span class="built_in">av_hwframe_transfer_data</span>(sw_frame, frame, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">sws_scale</span>(conversion_ctx, sw_frame-&gt;data, sw_frame-&gt;linesize, </span><br><span class="line">          <span class="number">0</span>, sw_frame-&gt;height, dst_data, dst_linesize);</span><br><span class="line">sw_frame-&gt;data = dst_data</span><br><span class="line">sw_frame-&gt;linesize = dst_linesize</span><br><span class="line">sw_frame-&gt;pix_fmt = AV_PIX_FMT_RGBA</span><br><span class="line">sw_frame-&gt;width = DST_WIDTH</span><br><span class="line">sw_frame-&gt;height = DST_HEIGHT</span><br></pre></td></tr></table></figure>

<p>这样能正常工作，但作为一个长期解决方案有两个问题.</p>
<ol>
<li>我想从 AVFrame 得到是一个简单字节数组；使用”d3d11va” 给我们帧数据并不是简单字节数组。因此我将硬件名称改成 “dxva”. 通过这种方式，frame-&gt;data 就是 uint8_t* 形式的位图。目前它是有效的，但是作为一个长期解决方案，不使用 “d3d11va” 基本没抓住重点</li>
<li>当调用 sws_scale() 将帧转换成RGBA，我们需要将帧从GPU移动到CPU。确实，现在是有效的，但是很明显我们将这步移除</li>
</ol>
<p>所以无论如何都不是完美，但至少我们解出了帧，并以bitmap形式呈现到我们眼前。</p>
<h2 id="第三步：设置-DirectX11-渲染"><a href="#第三步：设置-DirectX11-渲染" class="headerlink" title="第三步：设置 DirectX11 渲染"></a>第三步：设置 DirectX11 渲染</h2><p>如果你还不知道，这是对你的忠告：DirectX11 是完全不同于 DirectX9，完全不同！</p>
<p>经过很多失败的尝试，我复制并粘贴了这个<a href="directxtutorial.com/Lesson.aspx?lessonid=11-4-5">示例</a>，这样我可以开始写代码了。之后将三角形编程了正方形的异常复杂的任务。</p>
<p>此外，我没有在运行时编译着色器，而是选择在编译时编译它们。有那么一瞬间，我想我必须包含一个第三方库才能做到这点。但是它只需要在CMakeList.txt文件中的几行代码。找到 fxc.exe 可执行文件，并使用适当的选项执行命令来编译着色器。（我使用 /Fh 将它们编译成自动生成的头文件）</p>
<h2 id="第四步：交换纹理颜色"><a href="#第四步：交换纹理颜色" class="headerlink" title="第四步：交换纹理颜色"></a>第四步：交换纹理颜色</h2><p>当我得到一个彩虹方块，只需在定义的输入布局中为 TEXCOORD 切换成 COLOR即可。显然，这意味着要改变一些事情：</p>
<ol>
<li>顶点结构现在有 <code>XMFLOAT2</code> (<em>x, y</em>)  对应纹理坐标映射值为 <code>XMFLOAT4</code> (<em>r</em>, <em>g</em>, <em>b</em>, <em>a</em>)</li>
<li>片段着色器需要从纹理中采样而不是我们直接提供颜色，这意味着我们需要一个 sampler</li>
<li>另外，<a target="_blank" rel="noopener" href="http://www.rastertek.com/dx11s2tut05.html">纹理坐标系和位置坐标系是不同的</a></li>
</ol>
<p>当我能渲染一张基础的静态图时，我知道我接近了，剩下的就是将实际位图从帧传输到共享纹理。</p>
<h2 id="第五步：渲染实际的帧"><a href="#第五步：渲染实际的帧" class="headerlink" title="第五步：渲染实际的帧"></a>第五步：渲染实际的帧</h2><p>因为我们的帧仍然是简单的RGBA字节数组，并且我们的 ID3D11Texture2D 是 DXGI_FORMAT_R8G8B8A8_UNORM 的格式。使用 memcpy 就可以了，我们需要根据计算得出来的数组长度：<code>width_in_pixels * height_in_pixels * bytes_per_pixel</code>.</p>
<p>注意我们同样需要调用device context’s <code>Map()</code> 获取能访问纹理底层数据的权限</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// decode and convert frame</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">int</span> BYTES_IN_RGBA_PIXEL = <span class="number">4</span>;</span><br><span class="line">D3D11_MAPPED_SUBRESOURCE ms;</span><br><span class="line">device_context-&gt;<span class="built_in">Map</span>(m_texture.<span class="built_in">Get</span>(), <span class="number">0</span>, D3D11_MAP_WRITE_DISCARD, <span class="number">0</span>, &amp;ms);</span><br><span class="line"><span class="built_in">memcpy</span>(ms.pData, frame-&gt;data[<span class="number">0</span>], frame-&gt;width * frame-&gt;height * BYTES_IN_RGBA_PIXEL);</span><br><span class="line">device_context-&gt;<span class="built_in">Unmap</span>(m_texture.<span class="built_in">Get</span>(), <span class="number">0</span>);</span><br><span class="line"><span class="comment">// clear the render target view, draw the indices, present the swapchain</span></span><br></pre></td></tr></table></figure>



<h2 id="第六步：渲染实际帧…-可能是正确的"><a href="#第六步：渲染实际帧…-可能是正确的" class="headerlink" title="第六步：渲染实际帧… 可能是正确的"></a>第六步：渲染实际帧… 可能是正确的</h2><p>从我的研究开始，我就知道使用 “d3d11va” 硬件加速解出来 AVFrame 可以使用 DirectX11 进行渲染。哪要怎么做呢？</p>
<p>我需要初始化 <strong>d3d11va hardware device context.</strong> 基本上，FFmpeg解码器需要了解它正在使用D3D11设备。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">AVBufferRef* hw_device_ctx = <span class="built_in">av_hwdevice_ctx_alloc</span>(AV_HWDEVICE_TYPE_D3D11VA);</span><br><span class="line">AVHWDeviceContext* device_ctx = <span class="keyword">reinterpret_cast</span>&lt;AVHWDeviceContext*&gt;(hw_device_ctx-&gt;data);</span><br><span class="line">AVD3D11VADeviceContext* d3d11va_device_ctx = <span class="keyword">reinterpret_cast</span>&lt;AVD3D11VADeviceContext*&gt;(device_ctx-&gt;hwctx);</span><br><span class="line"><span class="comment">// m_device is our ComPtr&lt;ID3D11Device&gt;</span></span><br><span class="line">d3d11va_device_ctx-&gt;device = m_device.<span class="built_in">Get</span>();</span><br><span class="line"><span class="comment">// codec_ctx is a pointer to our FFmpeg AVCodecContext</span></span><br><span class="line">codec_ctx-&gt;hw_device_ctx = <span class="built_in">av_buffer_ref</span>(hw_device_ctx);</span><br><span class="line"><span class="built_in">av_hwdevice_ctx_init</span>(codec_ctx-&gt;hw_device_ctx);</span><br></pre></td></tr></table></figure>

<p>所以现在，当我把解出来的帧传到渲染器时，不需要将他们传输到CPU上，并且也不要将它们转成RGBA。我们可以简单地这样做：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ComPtr&lt;ID3D11Texture2D&gt; texture = (ID3D11Texture2D*)frame-&gt;data[<span class="number">0</span>];</span><br></pre></td></tr></table></figure>

<p>但是我们完成了么，并没有，还差很多。</p>
<p>我们需要将像素格式转成GPU。我们的交换链并没有神奇地开始渲染NV12帧，这意味着从NV12到RGBA转换需要在某个地方进行。现在，它将在GPU中进行，具体来说是在着色器中进行。这是合乎逻辑的；我们不仅是对纹理进行采样，因为纹理格式不是RGBA。为了让我们的着色器为每个像素返回正确的RGBA值，它需要根据纹理的YUV值来计算。</p>
<p>加入另一个着色器资源视图。当这个RGBA片段着色器将单个着色器资源视图作为输入，但是NV12片段着色器实际上需要两个：色度和亮度。因此，我们因此将一个纹理拆分成两个着色器资源视图。（在此之前，我不明白为什么DirectX需要区分纹理和着色器资源视图。天哪，我很高兴他们这样做了）</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DXGI_FORMAT_R8_UNORM for NV12 luminance channel</span></span><br><span class="line">D3D11_SHADER_RESOURCE_VIEW_DESC luminance_desc = <span class="built_in">CD3D11_SHADER_RESOURCE_VIEW_DESC</span>(m_texture, D3D11_SRV_DIMENSION_TEXTURE2D, DXGI_FORMAT_R8_UNORM);</span><br><span class="line">m_device-&gt;<span class="built_in">CreateShaderResourceView</span>(m_texture, &amp;luminance_desc,  &amp;m_luminance_shader_resource_view); </span><br><span class="line"><span class="comment">// DXGI_FORMAT_R8G8_UNORM for NV12 chrominance channel</span></span><br><span class="line">D3D11_SHADER_RESOURCE_VIEW_DESC chrominance_desc = <span class="built_in">CD3D11_SHADER_RESOURCE_VIEW_DESC</span>(texture,  D3D11_SRV_DIMENSION_TEXTURE2D, DXGI_FORMAT_R8G8_UNORM);</span><br><span class="line">m_device-&gt;<span class="built_in">CreateShaderResourceView</span>(m_texture, &amp;chrominance_desc, &amp;m_chrominance_shader_resource_view);</span><br></pre></td></tr></table></figure>

<p>当然，我们还需要确保允许我们的片段着色器访问这些色度和亮度通道。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m_device_context-&gt;<span class="built_in">PSSetShaderResources</span>(<span class="number">0</span>, <span class="number">1</span>, m_luminance_shader_resource_view.<span class="built_in">GetAddressOf</span>());</span><br><span class="line">m_device_context-&gt;<span class="built_in">PSSetShaderResources</span>(<span class="number">1</span>, <span class="number">1</span>, m_chrominance_shader_resource_view.<span class="built_in">GetAddressOf</span>());</span><br></pre></td></tr></table></figure>

<p>我们需要将纹理作为共享资源打开，这个ID3D11Texture2D 对象作为渲染器资源视图和FFmpeg 解出来帧的桥梁。我们将新解出来的帧复制到 ID3D11Texture2D 并且从中提取着色器资源视图。它是一种共享资源。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ComPtr&lt;IDXGIResource&gt; dxgi_resource;</span><br><span class="line">m_texture-&gt;<span class="built_in">QueryInterface</span>(__uuidof(IDXGIResource), <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">void</span>**&gt;(dxgi_resource.<span class="built_in">GetAddressOf</span>()));</span><br><span class="line">dxgi_resource-&gt;<span class="built_in">GetSharedHandle</span>(&amp;m_shared_handle);</span><br><span class="line">m_device-&gt;<span class="built_in">OpenSharedResource</span>(m_shared_handle, __uuidof(ID3D11Texture2D), <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">void</span>**&gt;(m_texture.<span class="built_in">GetAddressOf</span>()));</span><br></pre></td></tr></table></figure>

<p>我们需要改变我们接收复制纹理的方式。很显然每次渲染一帧时创建新的着色器资源视图代价是高昂。而且 <code>memcpy</code> 不再是一个选择因为我们无法简单访问纹理数据。我认为通过调用像 <code>CopySubresourceRegion</code> DirectX  函数来复制解出来的帧到纹理资源</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ComPtr&lt;ID3D11Texture2D&gt; new_texture = (ID3D11Texture2D*)frame-&gt;data[<span class="number">0</span>];</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> texture_index = frame-&gt;data[<span class="number">1</span>];</span><br><span class="line">m_device_context-&gt;<span class="built_in">CopySubresourceRegion</span>(</span><br><span class="line">        m_texture.<span class="built_in">Get</span>(), <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, </span><br><span class="line">        new_texture.<span class="built_in">Get</span>(), texture_index, <span class="literal">nullptr</span>);</span><br></pre></td></tr></table></figure>

<p>通过这些更改，我可以放心的告别那些 <code>av_hwframe_transfer_data()</code>和 <code>sws_scale()</code>这些函数，并且终于，向完全集成的FFmpeg-DirectX11视频播放器问好。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/windows/" rel="tag"># windows</a>
              <a href="/tags/DirectX/" rel="tag"># DirectX</a>
              <a href="/tags/ffmpeg/" rel="tag"># ffmpeg</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/03/16/DirectX11Tutorial/" rel="prev" title="DirectX11 Tutorial">
                  <i class="fa fa-chevron-left"></i> DirectX11 Tutorial
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">mingxingren</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>




  





</body>
</html>
